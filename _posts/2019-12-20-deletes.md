---
layout: post
title: A Good Day to Hard Delete
date: '2019-10-12 15:12:11 -0400'
categories: SQL
---

The ways in which we can delete from a database is an important data warehousing concept, one you’d ideally master before an interview. It is not a matter of memorizing the definitions (which I copy from the internet for you in a few lines), but rather understanding the consequences of choosing one over the other. 

So what are these terms? They describe how a database (or a specific table) changes when a record should be deleted.

## What are the types of deletes?

**Hard Deletes** - The entire record is deleted from the table. After the delete, users will not be able to see that the record ever existed.
**Soft Deletes** - The record is not deleted, but a field on the table indicates that it is deleted. The field can be a boolean, such as `is_deleted` or a timestamp such as `deleted_timestamp`. It’s usually best if this field name is consistent across all tables so users can readily and dynamically find the non-deleted data set.

[Source](https://www.stitchdata.com/docs/replication/deleted-record-handling)


## When should we use hard deletes?

Hard deletes are not a good idea in an analytic data warehouse. Stakeholders expect to see a table with only relevant records; for analytical data warehouse users, `cats_dim` means “a list of cats who are currently active.” See the table below as a counter example:

| cat_id  | cat_name  | is_deleted  |
|---|---|---|
| 1  | Mac  |  N |
| 2  | Cheese  |  N |
| 3  | Sushi  | Y  |

An analyst, who hasn’t read all the field names, because there’s likely more than just the three provided, maybe quickly try to find the count of current cats with
`select count(*) from cats_dim`

This would give her three cats, instead of the real answer of two (of course we couldn’t adopt Sushi, although he was [cute](https://www.instagram.com/p/B6QpTtNpniF/). Our hearts are already full).

This isn’t the worst mistake in the world, but imagine instead of count(*) it was sum(revenue). Imagine it was reported to an executive. You see where I’m going with this.

So by convention, in a data warehouse, we do hard deletes. But that doesn’t mean we do them everywhere.

## When should we use soft deletes?

We know that hard deletes are helpful when users are expecting only current data, but there are other types of users out there. For us, the team that writes the ETL from source databases.

As part of the ETL, we query datasets from a source database either as a full extraction or incremental extraction. In a full extraction, we pull the entire dataset every time we need more data (the dataset usually a table, but it can be a report at an API endpoint). This is the most computationally expensive way to get data, but the easiest in terms of writing the extraction query and writing the loading queries.

In the case of an incremental extraction, we only query for the data we have not seen yet form the source. We may write this query using a metadata field that represents the last time that record was modified (I like to call this field last_modified_timestamp, but often you’ll see it called systimestamp or sysmodtimestamp by convention). In our extraction query, we effectively say “yesterday I got data up until 2019-01-01, please give me the data that has been updated since then.” This allows us to extract and load fewer rows, saving compute and storage if we store historical extractions.

So what happens if a source database does hard deletes? This forces us to do full loads. Why? We extract data a table called cat_hospitalization_fact in the source:


| cat_id  | cat_name  | hospitalization_date  | hospitalization_reason  |
last_modified_timestamp  |
|---|---|---|
| 1  | Mac  |  2019-12-17 | Ate thread from a sewing basket | 2019-12-18
| 2  | Cheese  | 2018-12-01 | Ate hair elastics | 2018-12-02
| 3  | Sushi  | 2019-12-18 | Neutering | 2019-12-19


If we incrementally extracted from this table on 2019-12-19, we received all three of those rows. Now let’s say we revisit the table on 2019-12-20:

| cat_id  | cat_name  | hospitalization_date  | hospitalization_reason  |
last_modified_timestamp  |
|---|---|---|
| 1  | Mac  |  2019-12-17 | Ate thread from a sewing basket | 2019-12-18
| 2  | Cheese  | 2018-12-01 | Ate hair elastics | 2018-12-02
| 5  | Tuna  | 2019-12-19 | Neutering | 2019-12-20

When we extract, we will get one new row about Tuna. While I’m sure Tuna is very cute, our table in our database will look like this:

| cat_id  | cat_name  | hospitalization_date  | hospitalization_reason  |
last_modified_timestamp  |
|---|---|---|
| 1  | Mac  |  2019-12-17 | Ate thread from a sewing basket | 2019-12-18
| 2  | Cheese  | 2018-12-01 | Ate hair elastics | 2018-12-02
| 3  | Sushi  | 2019-12-18 | Neutering | 2019-12-19
| 5  | Tuna  | 2019-12-19 | Neutering | 2019-12-20

which, when compared to the source, is wrong. For whatever reason, Sushi’s hospitalization was deleted. In order to know that Sushi was deleted, we would have had to set the extraction date back to 2019-12-18, but, since we have no way of knowing what records will be deleting, in reality we’d have to set the extraction date back to the beginning of time to catch all of them. This would just be a full load.

When a source database has hard deletes, we have to do a full extraction to ensure we don’t misrepresent the data. This is expensive, especially as the data grows. If the source database had used soft deletes, it would look like this:

| cat_id  | cat_name  | hospitalization_date  | hospitalization_reason  | is_deleted | last_modified_timestamp 
|---|---|---|
| 1  | Mac  |  2019-12-17 | Ate thread from a sewing basket | N |2019-12-18
| 2  | Cheese  | 2018-12-01 | Ate hair elastics | N | 2018-12-02
| 3  | Sushi  | 2019-12-18 | Neutering | Y | 2019-12-20
| 5  | Tuna  | 2019-12-19 | Neutering | N | 2019-12-20

When we extracted the data for the second time (on 2019-12-20), we would have received:

| cat_id  | cat_name  | hospitalization_date  | hospitalization_reason  | is_deleted | last_modified_timestamp 
|---|---|---|
| 3  | Sushi  | 2019-12-18 | Neutering | Y | 2019-12-20
| 5  | Tuna  | 2019-12-19 | Neutering | N | 2019-12-20

This would have indicated to us that Sushi’s record was deleted without having to pull the entire dataset.  We can keep our incremental loads but not overstate data.

Looking at it from the perspective of the source database owners, another advantage of soft deletes is that they are easier to undelete. 

So what do we do once we have this soft delete? It’s easy, we can use it in the merge statement (this example is [Snowflake specific](https://docs.snowflake.net/manuals/sql-reference/sql/merge.html)). 

Our merge statement would look like this:

```
MERGE INTO cat_hospitalization_fact as t
USING source_data as s
ON t.cat_id = s.cat id
AND t.hospitalization_date = s.hospitalization_date
when matched then update set 
t.cat_name  = s.cat_name,
t.hospitalization_reason = s.hospitalization_reason,
when not matched then insert 
(cat_id, cat_name, hospitalization_reason, hospitalization_date)
values (s.cat_id, s.cat_name, s.hospitalization_reason, s.hospitalization_date)
when matched and s.is_delete = ‘Y’ then delete
```

Notice the last line-- we can use the soft delete from the source database to delete the record from our table. With hard deletes, we cannot do this; the absence of a row can’t create a delete in a merge, only a field indicating its deletion. In the case of hard deletes, we have to do a separate [DELETE statement](https://docs.snowflake.net/manuals/sql-reference/sql/delete.html).


## Conclusion
There is no clear winner between soft deletes and hard deletes; each has its own usage and advantages. That being said, and I can’t stress this enough, do not let your cats eat thread. Can I have four thousand dollars?

<figure >
<img src="https://github.com/alisaraa/alisaraa.github.io/blob/master/images/cone_head.png?raw=true" alt="Two cats on a laundry machine"  height="300">
<br>My little cone head cat after surgery to get thread removed from his intestines 
</figure>
